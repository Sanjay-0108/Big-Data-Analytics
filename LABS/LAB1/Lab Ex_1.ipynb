{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9437ab-0999-4ab6-a5a5-98de19d61aff",
   "metadata": {},
   "source": [
    "# <div style=\"text-align:center;\">Lab Exercise 1:  PathFinding and Regions</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03d45d-f550-48dd-af88-a8945c0e263a",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "In the realm of digital image processing, understanding pixel connectivity and identifying distinct regions within an image are fundamental components of effective image analysis. As images are essentially composed of a grid of pixels, each with an associated intensity value, analyzing the spatial relationships between these pixels becomes crucial in various applications, including computer vision, object detection, medical imaging, and pattern recognition.\n",
    "\n",
    "Connectivity defines how pixels relate to one another based on their adjacency, significantly influencing how we interpret and manipulate images. The classification of pixels into connected groups helps in identifying objects, edges, and areas of interest. In this report, we will explore two essential tasks that delve into pixel connectivity and region identification:\n",
    "\n",
    "1. **Task 1:** Finding digital paths between pixels using three distinct types of adjacency rules: **4-path**, **8-path**, and **m-path**. Each of these paths offers different ways of connecting pixels based on their arrangement. The 4-path focuses solely on horizontal and vertical connections, while the 8-path expands this by including diagonal connections. The m-path combines elements of both but imposes additional constraints on diagonal connectivity. Understanding these paths enables us to traverse images more effectively, allowing for accurate navigation through pixel arrangements and facilitating tasks such as segmentation and feature extraction.\n",
    "\n",
    "2. **Task 2:** Identifying distinct regions in a binary image and determining whether these regions are adjacent or disjoint. Regions are formed by groups of connected pixels that share the same intensity value (in this case, `1`). Analyzing the adjacency of these regions is crucial for understanding the structure of an image and can significantly impact further processing tasks. For instance, adjacent regions may indicate potential overlaps or relationships between objects in an image, while disjoint regions could represent separate entities.\n",
    "\n",
    "The culmination of these tasks provides a comprehensive framework for analyzing images at both the micro and macro levels. By understanding pixel connectivity and the formation of regions, we can leverage these insights to enhance various image processing techniques. Whether in autonomous vehicles for obstacle detection, in medical imaging for tumor identification, or in social media for image recognition, mastering pixel adjacency and region identification is pivotal for achieving accurate and reliable outcomes.\n",
    "\n",
    "Through this report, we aim to illustrate the importance of pixel paths and region connectivity in digital images, providing a foundation for further exploration into more complex image processing algorithms and methodologies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd9feb-e311-44a1-9770-b5d0f5adf872",
   "metadata": {},
   "source": [
    "## Concepts Used\n",
    "\n",
    "## 1. 4- Path Adjacency:\n",
    "In 4-path adjacency, two pixels are considered connected if they share a common edge. This means that only the pixels immediately above, below, to the left, or to the right of a given pixel are regarded as its neighbors. This connectivity is particularly useful for traversing pixel arrangements in a grid layout.\n",
    "\n",
    "For a pixel located at coordinates `(x, y)`, the 4-path neighbors are:\n",
    "  - `(x-1, y)` (above)\n",
    "  - `(x+1, y)` (below)\n",
    "  - `(x, y-1)` (left)\n",
    "  - `(x, y+1)` (right)\n",
    "\n",
    "\n",
    "\n",
    "## 2.8- Path Adjacency:\n",
    "\n",
    "In 8-path adjacency, two pixels are considered connected if they share a common edge or corner. This means that a pixel can connect to its immediate horizontal, vertical, and diagonal neighbors, providing a more comprehensive way to traverse pixel arrangements.\n",
    "\n",
    "For a pixel at `(x, y)`, the 8-path neighbors include:\n",
    "- Horizontal/Vertical neighbors: `(x-1, y)`, `(x+1, y)`, `(x, y-1)`, `(x, y+1)`\n",
    "- Diagonal neighbors: `(x-1, y-1)`, `(x-1, y+1)`, `(x+1, y-1)`, `(x+1, y+1)`\n",
    "\n",
    "\n",
    "## 3. m-Path Adjacency:  \n",
    "The m-path adjacency model allows diagonal connections between pixels but only under specific conditions. A diagonal connection is permitted if the immediate horizontal and vertical neighbors of the pixels involved are not connected. This model provides a balance between the strict 4-path and the more lenient 8-path connections.\n",
    "\n",
    "For a pixel at `(x, y)`, a diagonal connection to `(x-1, y-1)` is only valid if:\n",
    "- The pixel above `(x-1, y)` and the pixel to the left `(x, y-1)` are not connected.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37287e-a94a-4c25-89ae-18d603378227",
   "metadata": {},
   "source": [
    "Consider the following binary image:\n",
    "\n",
    "![Data Heatmap](1.png)\n",
    "\n",
    "\n",
    "- **4 path Adjacency:**\n",
    "  Starting from pixel `(1, 1)`, the traversable pixels using 4-path are:\n",
    "- From `(1, 1)` → `(0, 1)` (not traversable since it's `0`)\n",
    "- From `(1, 1)` → `(2, 1)` (not traversable since it's `0`)\n",
    "- From `(1, 1)` → `(1, 0)` (traversable)\n",
    "- From `(1, 1)` → `(1, 2)` (traversable)\n",
    "\n",
    "- **8 path Adjacency:**\n",
    "Starting from pixel `(1, 1)`, the traversable pixels using 8-path are:\n",
    "- From `(1, 1)` → `(0, 1)` (not traversable since it's `0`)\n",
    "- From `(1, 1)` → `(2, 1)` (not traversable since it's `0`)\n",
    "- From `(1, 1)` → `(1, 0)` (traversable)\n",
    "- From `(1, 1)` → `(1, 2)` (traversable)\n",
    "- From `(1, 1)` → `(0, 0)` (traversable)\n",
    "- From `(1, 1)` → `(0, 2)` (traversable)\n",
    "- From `(1, 1)` → `(2, 0)` (traversable)\n",
    "- From `(1, 1)` → `(2, 2)` (traversable)\n",
    "\n",
    "- **m path adjacency:**\n",
    "- Starting from pixel `(1, 1)`, the traversable pixels using m-path are:\n",
    "- From `(1, 1)` → `(1, 0)` (traversable)\n",
    "- From `(1, 1)` → `(1, 2)` (traversable)\n",
    "- From `(1, 1)` → `(0, 0)` (traversable if `(0, 1)` and `(1, 0)` are not connected)\n",
    "- From `(1, 1)` → `(0, 2)` (traversable if `(0, 1)` and `(1, 2)` are not connected)\n",
    "- From `(1, 1)` → `(2, 0)` (traversable if `(2, 1)` and `(1, 0)` are not connected)\n",
    "- From `(1, 1)` → `(2, 2)` (traversable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd46cd-e947-4749-b24e-2baf94107458",
   "metadata": {},
   "source": [
    "## 2. Finding Regions, Adjacent Regions, and Disjoint Regions\n",
    "\n",
    "**Region:** A region in a binary image is defined as a connected set of pixels that share the same intensity value. In our case, a region consists of pixels with the value `1`, which are considered \"on\" pixels. The connectedness can be defined based on the pixel adjacency rules (4-path, 8-path, or m-path).\n",
    "\n",
    "**Adjacent Regions:** Adjacent regions are defined as regions that are connected to each other either directly or indirectly through a shared edge or corner. In an 8-path adjacency, this includes diagonal connections.\n",
    " \n",
    "**Disjoint regions**: isjoint regions are regions that do not share any pixels or connections. They are completely separate from one another in the pixel grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5726d-2a91-471f-9536-be89b7dd1eb8",
   "metadata": {},
   "source": [
    "Consider the following binary image:\n",
    "\n",
    "![Data Heatmap](1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f6056-8fe9-4c9c-b1b4-ebedf4d348ae",
   "metadata": {},
   "source": [
    "In the given binary matrix:\n",
    "The regions with `1`s can be identified as follows:\n",
    "  - **Region 1**: `(0, 0), (1, 0), (1, 1), (1, 2), (2, 0)` - Connected pixels forming one region.\n",
    "  - **Region 2**: `(0, 2), (1, 2), (2, 2), (2, 3)` - Another distinct region.\n",
    "  - **Region 3**: `(4, 0), (4, 1), (4, 2), (4, 3)` - The bottom region..\n",
    "\n",
    "## Adjacent Regions:\n",
    "From the  example, let's analyze the regions:\n",
    "- **Region 1** and **Region 2** are adjacent because they share the pixel `(1, 2)`.\n",
    "## Disjoint Regions:\n",
    "  - **Region 3** is separate and not adjacent to the first two regions\n",
    "  - **Region 1** and **Region 3** (no shared pixels or connections)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad39fd3f-d441-4b3d-a97a-dc773d6c513d",
   "metadata": {},
   "source": [
    "## Question: Assume a binary image size 5 x 5 and perform the following: \n",
    "## Let V ={1} be the set of intensity value to define the adjacency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475695b-f5ca-4d81-a27b-a8080f551908",
   "metadata": {},
   "source": [
    "## (a) Find the following digital paths and print the path traversal from any source pixel ‘p’ to any other source pixel ‘q’:  4-Path, 8-Path and m-Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f37ad-7f8d-4ac6-bf23-f3fa2d8f1399",
   "metadata": {},
   "source": [
    "Now let us consider the following Binary image\n",
    "\n",
    "![Data Heatmap](3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd46fffd-37c7-45a6-873f-df351e0026a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348662f6-7056-47b3-9aef-7529533437b9",
   "metadata": {},
   "source": [
    "This cell imports the required libraries:\n",
    "- Imported NumPy to handle numerical operations and matrix representation of the image.\n",
    "- Imported deque for efficient queue operations, used in Breadth-First Search (BFS) for pathfinding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "450381bf-2362-43a0-ba24-4dff32547b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([ # Sample Binary image(5*5 Matrix) \n",
    "    [1, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 1],\n",
    "    [0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 0, 0]\n",
    "])\n",
    "start_pixel = (0, 0)  # Start at top-left\n",
    "end_pixel = (3, 3)    # End at (3, 3)\n",
    "v={1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93dd21-0f03-4a6a-9bab-2d85d9564989",
   "metadata": {},
   "source": [
    "- A 5x5 binary matrix was defined to represent an image, where 1 indicated pixels that were valid for path traversal, and 0 represented obstacles.\n",
    "The starting pixel was set to the top-left corner of the image at position (0, 0). The endpoint for the traversal was defined at the pixel located at (3, 3).\n",
    "- v = {1}: The valid intensity for traversal was explicitly set to 1, meaning only pixels with the value 1 were considered valid for pathfinding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd4d94-7b20-4512-9c9d-7ad64cc837af",
   "metadata": {},
   "source": [
    "#### Function to find all 4-paths using BFS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bc425c1-203d-4feb-8512-ec95be382bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_4(image, start, end):\n",
    "    directions_4 = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # 4-path directions\n",
    "    return bfs_all(image, start, end, directions_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de5679-7697-435a-83ef-62f43de4e862",
   "metadata": {},
   "source": [
    "The find_path_4 function was defined for identifying a path between the specified start and end points in the binary image using only vertical and horizontal moves. It defined the possible movement directions as up, down, left, and right by specifying coordinate changes in a list. The function then called the bfs algorithm, passing the image and these four directions, in order to compute the shortest path between the two points. This approach ensured that only 4-connected paths (no diagonals) were explored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c801a76-5324-4216-987c-66e57f578295",
   "metadata": {},
   "source": [
    "#### Function to find all 8-paths using BFS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "541990e4-dac1-40ab-bd84-8fd444322fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_8(image, start, end):\n",
    "    directions_8 = [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]  # 8-path directions\n",
    "    return bfs_all(image, start, end, directions_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbc79d-f4c3-4593-b488-c37b337f4a38",
   "metadata": {},
   "source": [
    "The find_path_8 function was designed to locate a path between the start and end points in the binary image, allowing both vertical, horizontal, and diagonal moves. It defined a list of directions that included movements in all eight possible directions (up, down, left, right, and diagonals). By passing these directions into the bfs function, it enabled the search for the shortest path that could traverse both 4-path and diagonal (8-path) moves, providing more flexibility in movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fba977-fdc0-4621-903a-9822d446b30a",
   "metadata": {},
   "source": [
    "### Function to find m-path (prioritizes 4-path, then uses diagonal moves if needed):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "509c0ebf-0bf8-438a-b426-f34ca0378268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths_m(image, start, end):\n",
    "    directions_4 = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # 4-path directions\n",
    "    directions_8 = [(-1, -1), (-1, 1), (1, -1), (1, 1)]  # Diagonal directions (8-path)\n",
    "    return bfs_all_m(image, start, end, directions_4, directions_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ee0b15-edd8-4c1a-9996-8d643960a54a",
   "metadata": {},
   "source": [
    "The find_path_m function was developed to find the \"m-path,\" which prioritized 4-path movements (vertical and horizontal) first and used diagonal moves (8-path) only if necessary. It defined separate lists of directions for 4-path and 8-path moves. These two sets of directions were then passed into the bfs_m function, which handled the pathfinding logic, ensuring that 4-path moves were attempted before diagonal movements were considered for finding the shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f7bb285-9cd3-47f3-8ac3-ac07b752953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_all(image, start, end, directions): # BFS implementation to find all paths\n",
    "    rows, cols = image.shape\n",
    "    queue = deque([(start, [start])])  # Queue stores (current node, current path)\n",
    "    all_paths = []  # To collect all paths\n",
    "\n",
    "    while queue:\n",
    "        current, path = queue.popleft()\n",
    "\n",
    "        # If we reached the end, save the path\n",
    "        if current == end:\n",
    "            all_paths.append(path)\n",
    "            continue  # Continue to explore other paths\n",
    "\n",
    "        # Explore neighbors\n",
    "        for direction in directions:\n",
    "            nr, nc = current[0] + direction[0], current[1] + direction[1]\n",
    "            if (0 <= nr < rows and 0 <= nc < cols and \n",
    "                image[nr, nc] == 1 and (nr, nc) not in path):\n",
    "                # Add new path to the queue\n",
    "                queue.append(((nr, nc), path + [(nr, nc)]))  \n",
    "\n",
    "    return all_paths  # Return all paths found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382998f-ab58-420f-af10-df2b96101f11",
   "metadata": {},
   "source": [
    "The bfs_all function implements a breadth-first search (BFS) algorithm to find all possible paths from a given start pixel to an end pixel in a binary image represented as a 2D array. The function initializes a queue that stores tuples consisting of the current pixel and the path taken to reach it. As it explores each pixel, it checks if the current pixel matches the end pixel; if so, it appends the path to the list of all paths found. The function then examines all neighboring pixels based on the specified movement directions. If a neighboring pixel is valid (i.e., it is within bounds, has a value of 1, and has not already been visited in the current path), the function adds it to the queue along with the updated path. This process continues until all paths to the end pixel have been explored, at which point the function returns a list of all valid paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "598ecb73-d04f-4cfa-aef1-3f768abc54ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bfs_all_m(image, start, end, directions_4, directions_8): # BFS with priority to 4-path first, then 8-path (diagonal) moves\n",
    "    rows, cols = image.shape\n",
    "    queue = deque([(start, [start])])  # Queue stores (current node, current path)\n",
    "    all_paths = []  # To collect all paths\n",
    "\n",
    "    while queue:\n",
    "        current, path = queue.popleft()\n",
    "\n",
    "        # If we reached the end, save the path\n",
    "        if current == end:\n",
    "            all_paths.append(path)\n",
    "            continue  # Continue to explore other paths\n",
    "\n",
    "        # Check for 4-path neighbors\n",
    "        neighbors_found = False  # Track if any 4-path neighbors are found\n",
    "        for direction in directions_4:\n",
    "            nr, nc = current[0] + direction[0], current[1] + direction[1]\n",
    "            if (0 <= nr < rows and 0 <= nc < cols and \n",
    "                image[nr, nc] == 1 and (nr, nc) not in path):\n",
    "                queue.append(((nr, nc), path + [(nr, nc)]))  # Continue with 4-path\n",
    "                neighbors_found = True  # Mark that we found 4-path neighbors\n",
    "\n",
    "        # Only check 8-path neighbors if no 4-path neighbors were found\n",
    "        if not neighbors_found:\n",
    "            for direction in directions_8:\n",
    "                nr, nc = current[0] + direction[0], current[1] + direction[1]\n",
    "                if (0 <= nr < rows and 0 <= nc < cols and \n",
    "                    image[nr, nc] == 1 and (nr, nc) not in path):\n",
    "                    queue.append(((nr, nc), path + [(nr, nc)]))  # Continue exploring diagonals\n",
    "\n",
    "    return all_paths  # Return all paths found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef79ead-e054-47f0-bb12-a56016caa428",
   "metadata": {},
   "source": [
    "The bfs_all_m function enhances the BFS algorithm by prioritizing 4-path movements (up, down, left, right) over 8-path movements (including diagonals) when searching for all possible paths from a start pixel to an end pixel in a binary image. The function begins by initializing a queue with the starting pixel and an empty path list. As it processes each pixel, it first checks for 4-path neighbors. If any valid neighbors are found (i.e., within the image boundaries, have a value of 1, and are not already included in the current path), these neighbors are added to the queue, and the search continues without checking the diagonal neighbors. However, if no 4-path neighbors are found, the function then explores diagonal (8-path) neighbors. When the end pixel is reached, the complete path is saved to a list of all paths. This approach ensures that paths are prioritized based on the specified movement directions while allowing for a thorough exploration of possible routes in the image. Finally, the function returns all the discovered paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4172c1-0d3d-429f-a30f-b216a53d6ce8",
   "metadata": {},
   "source": [
    "#### Printng all 4-paths, 8-paths, and m-paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "922edea2-1233-457d-a6fa-1d5523da3d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 4-paths:\n",
      "\n",
      "All 8-paths:\n",
      "(0, 0) -> (1, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 0) -> (1, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 0) -> (2, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 0) -> (2, 1) -> (1, 1) -> (2, 2) -> (3, 3)\n",
      "(0, 0) -> (1, 1) -> (1, 0) -> (2, 1) -> (2, 2) -> (3, 3)\n",
      "\n",
      "All m-paths:\n",
      "(0, 0) -> (1, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Find and print all 4-paths, 8-paths, and m-paths\n",
    "all_paths_4 = find_all_paths_4(image, start_pixel, end_pixel)\n",
    "print(\"All 4-paths:\")\n",
    "for path in all_paths_4:\n",
    "    print(\" -> \".join(str(p) for p in path))\n",
    "\n",
    "all_paths_8 = find_all_paths_8(image, start_pixel, end_pixel)\n",
    "print(\"\\nAll 8-paths:\")\n",
    "for path in all_paths_8:\n",
    "    print(\" -> \".join(str(p) for p in path))\n",
    "\n",
    "all_paths_m = find_all_paths_m(image, start_pixel, end_pixel)\n",
    "print(\"\\nAll m-paths:\")\n",
    "for path in all_paths_m:\n",
    "    print(\" -> \".join(str(p) for p in path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d9e03-ec33-4eb0-9ba4-eab99ae65e8e",
   "metadata": {},
   "source": [
    "#### Function to get user input for start and end pixels separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57be9c8f-d46d-421f-bbc1-e319df4d13b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start pixel (row,col) separated by comma (e.g., '0,0'):  1,0\n",
      "Enter the end pixel (row,col) separated by comma (e.g., '3,3'):  3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All 4-paths:\n",
      "\n",
      "All 8-paths:\n",
      "(1, 0) -> (1, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (2, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (0, 0) -> (1, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (2, 1) -> (1, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (0, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "\n",
      "All m-paths:\n",
      "(1, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n",
      "(1, 0) -> (0, 0) -> (1, 1) -> (2, 1) -> (2, 2) -> (3, 3) -> (3, 4)\n"
     ]
    }
   ],
   "source": [
    "def get_user_input():\n",
    "    while True:\n",
    "        try:\n",
    "            start_input = input(\"Enter the start pixel (row,col) separated by comma (e.g., '0,0'): \")\n",
    "            start_x, start_y = map(int, start_input.split(','))\n",
    "            if 0 <= start_x < image.shape[0] and 0 <= start_y < image.shape[1]:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid start pixel. Please enter values within the image bounds.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input for start pixel. Please enter integer values.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            end_input = input(\"Enter the end pixel (row,col) separated by comma (e.g., '3,3'): \")\n",
    "            end_x, end_y = map(int, end_input.split(','))\n",
    "            if 0 <= end_x < image.shape[0] and 0 <= end_y < image.shape[1]:\n",
    "                return (start_x, start_y), (end_x, end_y)\n",
    "            else:\n",
    "                print(\"Invalid end pixel. Please enter values within the image bounds.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input for end pixel. Please enter integer values.\")\n",
    "\n",
    "# Get start and end pixels from user\n",
    "start_pixel, end_pixel = get_user_input()\n",
    "\n",
    "# Find and print all 4-paths, 8-paths, and m-paths\n",
    "all_paths_4 = find_all_paths_4(image, start_pixel, end_pixel)\n",
    "print(\"\\nAll 4-paths:\")\n",
    "for path in all_paths_4:\n",
    "    print(\" -> \".join(str(p) for p in path))\n",
    "\n",
    "all_paths_8 = find_all_paths_8(image, start_pixel, end_pixel)\n",
    "print(\"\\nAll 8-paths:\")\n",
    "for path in all_paths_8:\n",
    "    print(\" -> \".join(str(p) for p in path))\n",
    "\n",
    "all_paths_m = find_all_paths_m(image, start_pixel, end_pixel)\n",
    "print(\"\\nAll m-paths:\")\n",
    "for path in all_paths_m:\n",
    "    print(\" -> \".join(str(p) for p in path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293227d-eaf1-4c99-9343-d5b1ac9eea0f",
   "metadata": {},
   "source": [
    "## (b) Find all the regions present in the image and declare the adjacent regions anddisjoint regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250e0c6-d809-432a-8e3c-c02b4780e2f0",
   "metadata": {},
   "source": [
    "#### Function to Label Regions Using BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c799bea9-1039-4fd1-97c1-f1aa908d4afe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def label_regions(image, directions):\n",
    "    rows, cols = image.shape\n",
    "    labeled_image = np.zeros_like(image)  # To store labeled regions\n",
    "    label = 1  # Starting label\n",
    "    regions = {}  # Dictionary to hold regions\n",
    "\n",
    "    def bfs(start):\n",
    "        queue = deque([start])\n",
    "        region = []\n",
    "        labeled_image[start] = label\n",
    "        region.append(start)\n",
    "\n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            for direction in directions:\n",
    "                nr, nc = current[0] + direction[0], current[1] + direction[1]\n",
    "                if 0 <= nr < rows and 0 <= nc < cols and image[nr, nc] == 1 and labeled_image[nr, nc] == 0:\n",
    "                    queue.append((nr, nc))\n",
    "                    labeled_image[nr, nc] = label\n",
    "                    region.append((nr, nc))\n",
    "        \n",
    "        return region\n",
    "\n",
    "    # Find all regions\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if image[r, c] == 1 and labeled_image[r, c] == 0:\n",
    "                regions[label] = bfs((r, c))\n",
    "                label += 1\n",
    "\n",
    "    return labeled_image, regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f4d11-82c6-452b-83e8-84e0f7c009e6",
   "metadata": {},
   "source": [
    "The label_regions function identifies and labels distinct regions within a binary image based on the provided adjacency directions (either 4-path or 8-path). It initializes a new image to store the labels and uses a breadth-first search (BFS) approach to explore connected pixels that belong to the same region. The function begins by defining a nested bfs function, which processes each pixel's neighbors, marking them with the same label and adding them to the current region until all connected pixels are visited. The outer loop iterates through every pixel in the image; when it encounters an unvisited pixel that is part of a region (value of 1), it calls the BFS function to label that region and store its coordinates. This process continues until all regions are identified and labeled, returning both the labeled image and a dictionary containing the coordinates of each labeled region. This systematic approach ensures that all connected components are accurately detected and distinguished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a378d-8d6d-47e9-85eb-86938587f86c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16947347-4c45-43f0-a972-1061466a8ff7",
   "metadata": {},
   "source": [
    "#### Function to check if two regions are adjacent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829cf91-75f0-4d5e-8fff-c586ea74663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if two regions are adjacent\n",
    "def are_adjacent(region1, region2, directions):\n",
    "    for r1, c1 in region1:\n",
    "        for direction in directions:\n",
    "            nr, nc = r1 + direction[0], c1 + direction[1]\n",
    "            if (nr, nc) in region2:\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51449df5-36f4-446e-a292-64e40d65ec9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a597e31-2685-48d4-96d5-68dfe0cb222e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b7963cb-c0e9-4148-96e2-66cae9c457ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 4-path adjacency:\n",
      "\n",
      "Regions formed using 4-path adjacency:\n",
      "\n",
      "Region 1: [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2)]\n",
      "Region 2: [(0, 4), (1, 4)]\n",
      "Region 3: [(3, 3), (3, 4)]\n",
      "Region 4: [(4, 0), (4, 1)]\n",
      "\n",
      "Adjacency between regions (4-path):\n",
      "Region 1 is disjoint from Region 2\n",
      "Region 1 is disjoint from Region 3\n",
      "Region 1 is disjoint from Region 4\n",
      "Region 2 is disjoint from Region 3\n",
      "Region 2 is disjoint from Region 4\n",
      "Region 3 is disjoint from Region 4\n",
      "\n",
      "Analyzing 8-path adjacency:\n",
      "\n",
      "Regions formed using 8-path adjacency:\n",
      "\n",
      "Region 1: [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (3, 3), (3, 4)]\n",
      "Region 2: [(0, 4), (1, 4)]\n",
      "Region 3: [(4, 0), (4, 1)]\n",
      "\n",
      "Adjacency between regions (8-path):\n",
      "Region 1 is disjoint from Region 2\n",
      "Region 1 is disjoint from Region 3\n",
      "Region 2 is disjoint from Region 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the 4-path and 8-path directions\n",
    "directions_4 = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Up, down, left, right\n",
    "directions_8 = directions_4 + [(-1, -1), (-1, 1), (1, -1), (1, 1)]  # Adding diagonals\n",
    "\n",
    "# Function to label all regions in the image using BFS\n",
    "def label_regions(image, directions):\n",
    "    rows, cols = image.shape\n",
    "    labeled_image = np.zeros_like(image)  # To store labeled regions\n",
    "    label = 1  # Starting label\n",
    "    regions = {}  # Dictionary to hold regions\n",
    "\n",
    "    def bfs(start):\n",
    "        queue = deque([start])\n",
    "        region = []\n",
    "        labeled_image[start] = label\n",
    "        region.append(start)\n",
    "\n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            for direction in directions:\n",
    "                nr, nc = current[0] + direction[0], current[1] + direction[1]\n",
    "                if 0 <= nr < rows and 0 <= nc < cols and image[nr, nc] == 1 and labeled_image[nr, nc] == 0:\n",
    "                    queue.append((nr, nc))\n",
    "                    labeled_image[nr, nc] = label\n",
    "                    region.append((nr, nc))\n",
    "        \n",
    "        return region\n",
    "\n",
    "    # Find all regions\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if image[r, c] == 1 and labeled_image[r, c] == 0:\n",
    "                regions[label] = bfs((r, c))\n",
    "                label += 1\n",
    "\n",
    "    return labeled_image, regions\n",
    "\n",
    "# Function to check if two regions are adjacent\n",
    "def are_adjacent(region1, region2, directions):\n",
    "    for r1, c1 in region1:\n",
    "        for direction in directions:\n",
    "            nr, nc = r1 + direction[0], c1 + direction[1]\n",
    "            if (nr, nc) in region2:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to analyze and print all regions and their relationships\n",
    "def analyze_regions(image, directions, adjacency_type=\"4-path\"):\n",
    "    labeled_image, regions = label_regions(image, directions)\n",
    "    \n",
    "    print(f\"\\nRegions formed using {adjacency_type} adjacency:\\n\")\n",
    "    for label, region in regions.items():\n",
    "        print(f\"Region {label}: {region}\")\n",
    "\n",
    "    # Checking adjacency between regions\n",
    "    print(f\"\\nAdjacency between regions ({adjacency_type}):\")\n",
    "    region_labels = list(regions.keys())\n",
    "    for i in range(len(region_labels)):\n",
    "        for j in range(i + 1, len(region_labels)):\n",
    "            region1 = regions[region_labels[i]]\n",
    "            region2 = regions[region_labels[j]]\n",
    "            if are_adjacent(region1, region2, directions):\n",
    "                print(f\"Region {region_labels[i]} is adjacent to Region {region_labels[j]}\")\n",
    "            else:\n",
    "                print(f\"Region {region_labels[i]} is disjoint from Region {region_labels[j]}\")\n",
    "\n",
    "# Run the analysis for both 4-path and 8-path\n",
    "print(\"Analyzing 4-path adjacency:\")\n",
    "analyze_regions(image, directions_4, \"4-path\")\n",
    "\n",
    "print(\"\\nAnalyzing 8-path adjacency:\")\n",
    "analyze_regions(image, directions_8, \"8-path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393edef0-03dc-41cd-9368-f3b5a0479098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea1c95-624b-43af-9ac7-1589969ba0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259427d3-9c93-4689-996b-9cf24a4d87db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1656e28-11d5-4390-8c7c-9011af23bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1a693e-d73b-489b-a8af-c2ce6848a91a",
   "metadata": {},
   "source": [
    "#### Function to Check Adjacency Between Regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10996995-28d4-49bb-93d9-f7211fb3072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if two regions are adjacent\n",
    "def are_adjacent(region1, region2, directions):\n",
    "    for r1, c1 in region1:\n",
    "        for direction in directions:\n",
    "            nr, nc = r1 + direction[0], c1 + direction[1]\n",
    "            if (nr, nc) in region2:\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287582d3-118b-42f7-9d50-b85dec28cfcc",
   "metadata": {},
   "source": [
    "The are_adjacent function determines whether two specified regions in a binary image are adjacent to each other based on given directional criteria. It takes in two regions, region1 and region2, along with the directions (either 4-path or 8-path) for movement. The function iterates through each coordinate in region1, and for each coordinate, it checks all possible neighboring positions based on the provided directions. If any neighboring position of a coordinate from region1 corresponds to a coordinate in region2, the function returns True, indicating that the regions are adjacent. If no such neighboring coordinates are found after checking all possibilities, the function returns False, confirming that the regions are disjoint. This check is crucial for understanding spatial relationships in the analyzed image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311cde9-933e-481b-9b2a-c0a99f0d17d3",
   "metadata": {},
   "source": [
    "#### Function to Analyze and Print Regions and Their Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d99088b7-1228-46b9-bc87-6f4ae15b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_regions(image, directions, adjacency_type=\"4-path\"):\n",
    "    labeled_image, regions = label_regions(image, directions)\n",
    "    \n",
    "    print(f\"\\nRegions formed using {adjacency_type} adjacency:\\n\")\n",
    "    for label, region in regions.items():\n",
    "        print(f\"Region {label}: {region}\")\n",
    "\n",
    "    # Checking adjacency between regions\n",
    "    print(f\"\\nAdjacency between regions ({adjacency_type}):\")\n",
    "    region_labels = list(regions.keys())\n",
    "    for i in range(len(region_labels)):\n",
    "        for j in range(i + 1, len(region_labels)):\n",
    "            region1 = regions[region_labels[i]]\n",
    "            region2 = regions[region_labels[j]]\n",
    "            if are_adjacent(region1, region2, directions):\n",
    "                print(f\"Region {region_labels[i]} is adjacent to Region {region_labels[j]}\")\n",
    "            else:\n",
    "                print(f\"Region {region_labels[i]} is disjoint from Region {region_labels[j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8678464-c812-4a5e-8101-85ea3f8fb988",
   "metadata": {},
   "source": [
    "The analyze_regions function examines and categorizes regions within a binary image based on specified adjacency criteria (either 4-path or 8-path). First, it calls the label_regions function to identify and label distinct regions in the image, storing them in a dictionary. It then prints each identified region, providing clarity on their coordinates. Following this, the function evaluates the adjacency between all pairs of regions by iterating through the labeled regions and using the are_adjacent function to check for shared boundaries. Finally, it outputs whether each pair of regions is adjacent or disjoint, enhancing the understanding of spatial relationships between different regions in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd7575-4380-4fbd-9cf1-e62ea6e51ced",
   "metadata": {},
   "source": [
    "\n",
    "#### Running the Analysis for Both 4-path and 8-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90487201-5276-402f-97e9-5019d8cd9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 4-path adjacency:\n",
      "\n",
      "Regions formed using 4-path adjacency:\n",
      "\n",
      "Region 1: [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2)]\n",
      "Region 2: [(0, 2)]\n",
      "Region 3: [(0, 4), (1, 4)]\n",
      "Region 4: [(3, 3), (3, 4)]\n",
      "Region 5: [(4, 0), (4, 1)]\n",
      "\n",
      "Adjacency between regions (4-path):\n",
      "Region 1 is disjoint from Region 2\n",
      "Region 1 is disjoint from Region 3\n",
      "Region 1 is disjoint from Region 4\n",
      "Region 1 is disjoint from Region 5\n",
      "Region 2 is disjoint from Region 3\n",
      "Region 2 is disjoint from Region 4\n",
      "Region 2 is disjoint from Region 5\n",
      "Region 3 is disjoint from Region 4\n",
      "Region 3 is disjoint from Region 5\n",
      "Region 4 is disjoint from Region 5\n",
      "\n",
      "Analyzing 8-path adjacency:\n",
      "\n",
      "Regions formed using 8-path adjacency:\n",
      "\n",
      "Region 1: [(0, 0), (1, 0), (1, 1), (2, 1), (0, 2), (2, 2), (3, 3), (3, 4)]\n",
      "Region 2: [(0, 4), (1, 4)]\n",
      "Region 3: [(4, 0), (4, 1)]\n",
      "\n",
      "Adjacency between regions (8-path):\n",
      "Region 1 is disjoint from Region 2\n",
      "Region 1 is disjoint from Region 3\n",
      "Region 2 is disjoint from Region 3\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis for both 4-path and 8-path\n",
    "print(\"Analyzing 4-path adjacency:\")\n",
    "analyze_regions(image, directions_4, \"4-path\")\n",
    "\n",
    "print(\"\\nAnalyzing 8-path adjacency:\")\n",
    "analyze_regions(image, directions_8, \"8-path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281515c5-36e4-400b-86b6-fbb0762eece6",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this report, we have thoroughly explored the critical aspects of pixel connectivity and region identification within digital images. Through **Task 1**, we examined how different types of digital paths—**4-path**, **8-path**, and **m-path**—provide distinct methods for traversing images based on pixel adjacency. Each path offers unique advantages in determining how pixels are connected, which plays a vital role in various image processing applications. For instance, understanding these paths can facilitate the segmentation of images, allowing for precise feature extraction and enabling algorithms to discern patterns and objects more effectively.\n",
    "\n",
    "**Task 2** built upon this foundation by identifying distinct regions in a binary image and analyzing the adjacency and disjoint characteristics of these regions. By leveraging pixel connectivity, we established a framework for understanding how pixels group together to form larger structures within an image. This analysis is particularly important in applications such as object detection, where identifying and differentiating between overlapping regions can significantly affect the performance of machine learning models and image classification systems.\n",
    "\n",
    "The insights gained from examining pixel paths and region adjacency are not just theoretical; they have practical implications across various domains. In medical imaging, for example, accurate identification of connected regions can aid in diagnosing conditions based on the shape and size of tumors. In autonomous systems, understanding the spatial relationships between objects can enhance navigation and obstacle detection capabilities. Additionally, in the realm of computer vision, these techniques are foundational for developing sophisticated algorithms that drive advancements in areas like augmented reality and facial recognition.\n",
    "\n",
    "In summary, this report underscores the importance of pixel connectivity and region identification in digital image processing. By mastering these concepts, we lay the groundwork for further exploration into advanced techniques, paving the way for innovative applications that harness the power of image analysis. The ability to accurately traverse images and identify significant regions is pivotal in transforming raw image data into meaningful insights, ultimately enhancing our interaction with the visual world.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
